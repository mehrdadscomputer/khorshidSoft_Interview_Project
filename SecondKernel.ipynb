{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "    1. check result in case of using stop-words\n",
    "    2. use over sampling to correct imbalance dataset problem. the result will definitely improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals # hazm\n",
    "\n",
    "import numpy as np # linear Algebra \n",
    "import pandas as pd # data Manipulation\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to show diagrams in cells\n",
    "%matplotlib inline\n",
    "\n",
    "# text preprocessing\n",
    "from string import punctuation\n",
    "\n",
    "# persian text processing\n",
    "from hazm import Normalizer, Lemmatizer, word_tokenize, Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/mehrdad/Downloads/Projects_Jupyter/KhorshidSoft_Interview_Project/'\n",
    "df_origin = pd.read_json(directory + 'sample_dataset.json.txt')\n",
    "df = df_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb87fb47e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_distribution = df.groupby('sentiment').count()\n",
    "sentiment_distribution.reset_index(inplace=True)\n",
    "sns.barplot(x='sentiment', y='comment', data=sentiment_distribution)\n",
    "plt.legend(labels=['0: Positive', '1: Negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing and cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalizing text - for example: removing Arabic ی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "df['comment'] = df['comment'].apply(lambda text: normalizer.normalize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing \\u200c character form text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = punctuation + '‌' # To remove \"\\u200c\" (shift+space) in persian text\n",
    "punctuation = punctuation + '۰۱۲۳۴۵۶۷۸۹' # To remove persian numbers\n",
    "punctuation = punctuation + '.،…' # To remove persian comma and full stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing punctuations form text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(word):\n",
    "    final_word = ''\n",
    "    for i in word:\n",
    "        if i not in punctuation:\n",
    "            final_word = final_word + i\n",
    "        else:\n",
    "            final_word = final_word + \" \"\n",
    "    return final_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['comment'].apply(lambda text: word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toeknToLemma(text):\n",
    "    mList = []\n",
    "    for i in text:\n",
    "        mList.append(lemmatizer.lemmatize(i))\n",
    "    return mList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "df['lemmas'] = df['tokens'].apply(lambda text: toeknToLemma(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing stop words\n",
    "Because our dataset is small, I want to keep data as much as I can, so I won't remove stop words.\n",
    "\n",
    "some important words like 'good' and 'bad' are in 'StopWords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(words):\n",
    "    df_persian_stop_words = pd.read_csv('STOPWORDS',\n",
    "                                    header=None)\n",
    "    df_persian_stop_words.columns = ['word']\n",
    "    persian_stop_words = []\n",
    "    \n",
    "    df_persian_stop_words['word'].apply(lambda x: persian_stop_words.append(x));\n",
    "    \n",
    "    result = [x for x in words if x not in persian_stop_words]\n",
    "    \n",
    "    del df_persian_stop_words, persian_stop_words\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stop_words'] = df['lemmas'].apply(lambda text: removeStopWords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 55740\n"
     ]
    }
   ],
   "source": [
    "all_tokens = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df['lemmas'][i])):\n",
    "        all_tokens.append(df['lemmas'][i][j])\n",
    "\n",
    "print('total tokens: {}'.format(len(all_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens(vocab size): 4702\n",
      "Most common words are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('و', 2491), ('از', 1342), ('به', 1170), ('که', 1050), ('خیلی', 994)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(all_tokens)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "\n",
    "print('total tokens(vocab size): {}'.format(len(vocab)))\n",
    "print('Most common words are:')\n",
    "counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for each in df['lemmas']:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in each])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 221\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "max_review_length = max(review_lens)\n",
    "print(len(df))\n",
    "print(len(reviews_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_be_removed = [i for i, value in enumerate(reviews_ints, 0)  if len(value) == 0]\n",
    "for i in range(len(df)):\n",
    "    if(i in indexes_to_be_removed):\n",
    "        df.drop(index=i, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out that review with 0 length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = [each for each in reviews_ints if len(each) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = max_review_length\n",
    "features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(reviews_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3199\n",
      "3199\n",
      "3199\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(reviews_ints))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3199, 221)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,   95,  337, 2260,   51,    2,   68,\n",
       "          92,   99,  176, 1647,  414,   12,   14,   26,    6, 1006,  551,\n",
       "          26,   40,   64,    1, 2261,   54,    4,   82,  321,  903,    1,\n",
       "         638,   64, 1007,  115,  119,  747,  808,   41,   13,   57,   35,\n",
       "           2,  191,  120,  137, 1318,   14,  588,    5,  473, 1008,   72,\n",
       "         108,   43,   80,    2,   10,   27,  681,   61,   68, 1648,   87,\n",
       "         109],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   21,   19,   68,   29,    6,  165,   82,\n",
       "          23]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building RNN model with word_embedding and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(2559, 221) \n",
      "Validation set: \t(320, 221) \n",
      "Test set: \t\t(320, 221)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 221, 200)          940600    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,061,101\n",
      "Trainable params: 1,061,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the model \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "embedding_vector_length = 200\n",
    "model = Sequential() \n",
    "model.add(Embedding(len(vocab)+1, embedding_vector_length, input_length=max_review_length)) \n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrdad/Downloads/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/mehrdad/Downloads/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2559 samples, validate on 320 samples\n",
      "Epoch 1/3\n",
      "2559/2559 [==============================] - 32s 13ms/step - loss: 0.5305 - accuracy: 0.7730 - val_loss: 0.4406 - val_accuracy: 0.7844\n",
      "Epoch 2/3\n",
      "2559/2559 [==============================] - 39s 15ms/step - loss: 0.3174 - accuracy: 0.8542 - val_loss: 0.3160 - val_accuracy: 0.8781\n",
      "Epoch 3/3\n",
      "2559/2559 [==============================] - 43s 17ms/step - loss: 0.1857 - accuracy: 0.9301 - val_loss: 0.3413 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb83173f9d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), nb_epoch=3, batch_size=64) #batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "scores = model.evaluate(test_x, test_y, verbose=0) \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = normalizer.normalize(text)\n",
    "    text = remove_punc(text)\n",
    "    text = word_tokenize(text)\n",
    "    text = toeknToLemma(text)\n",
    "    \n",
    "    reviews_int = [vocab_to_int[word] for word in text]\n",
    "    \n",
    "    seq_len = max_review_length\n",
    "    features = np.zeros(seq_len, dtype=int)\n",
    "#     for i in reviews_ints:\n",
    "    features[-len(reviews_int):] = np.array(reviews_int)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    1, 3860,   25,\n",
       "         13])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9789677]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = 'متاسفانه بخاطر تعریف های زیادی که ازش شده بود خریدم  اصلا روی جوش تاثیری نداره  پوست رو فوق العاده خشک و کدر میکنه '\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model\n",
    "    output interpretation:\n",
    "        near 1: negative\n",
    "        near 0: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "خیلی بده اصلا به درد نمیخوره\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.98242676]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 31\n",
    "print(df_origin['sentiment'][i])\n",
    "print(df_origin['comment'][i])\n",
    "\n",
    "review =  df_origin['comment'][i]\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "برای پوستای چرب واقعا ایده آل هستش  هم آبرسانی خوبی داره هم زود جذب میشه  بوش هم عالیه\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00049004]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 61\n",
    "print(df_origin['sentiment'][i])\n",
    "print(df_origin['comment'][i])\n",
    "\n",
    "review =  df_origin['comment'][i]\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "بسیار با کیفیت وسرعت شارز سریع برابی نوت   ممنون از دی جی کالا من یکی خریدم یکی هم هدیه دادن\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00302509]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1002\n",
    "print(df_origin['sentiment'][i])\n",
    "print(df_origin['comment'][i])\n",
    "\n",
    "review =  df_origin['comment'][i]\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 4 - answer is not good nor bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "اونجوری که انتظار داشتم  موهای زائد رو جدا نمیکنه از پوست  ولی در کل خوبه\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00201276]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1001\n",
    "print(df_origin['sentiment'][i])\n",
    "print(df_origin['comment'][i])\n",
    "\n",
    "review =  df_origin['comment'][i]\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 5 - answer is not good nor bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "من اینو استفاده کردم خاصیت آبرسانی و مرطوب کنندگی عالی و بدون چربی و سبک مناسب ساختار پوست آقایان و رایحه عالی  به سلامتی خود اهمیت بدهیم\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01065985]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2000\n",
    "print(df_origin['sentiment'][i])\n",
    "print(df_origin['comment'][i])\n",
    "\n",
    "review =  df_origin['comment'][i]\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 5 - answer is not good nor bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "به هیچ عنوان کارایی ندارد  تا وارد دندان شده پاره میشود و آزار دهنده است\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42215022]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3007\n",
    "print(df_origin['sentiment'][i])\n",
    "print(df_origin['comment'][i])\n",
    "\n",
    "review =  df_origin['comment'][i]\n",
    "review = clean_text(review)\n",
    "model.predict(review.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
